{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY7sOlNI2C0j",
        "outputId": "c2153889-c011-4944-8de3-40489a6df8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "++++\n",
            "2222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c6b0d395ab0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "333\n",
            "444\n",
            "55\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load MobileNet model\n",
        "mobileNetModel = tf.keras.applications.MobileNet()\n",
        "\n",
        "# Define the image path\n",
        "image_path = '/content/drive/MyDrive/dataSamples/'\n",
        "print('++++')\n",
        "# Function to prepare an image\n",
        "def prepare_image(file):\n",
        "    img = Image.open(image_path + file)\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = tf.image.convert_image_dtype(img_array, tf.float32)  # Convert to float32\n",
        "    img_array = tf.keras.applications.mobilenet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Specify the image file name\n",
        "image_file_name = '0001_000.jpeg'\n",
        "print('2222')\n",
        "# Prepare and predict on a single image\n",
        "preprocessed_image = prepare_image(image_file_name)\n",
        "results = mobileNetModel.predict(preprocessed_image)\n",
        "decoded_predictions = imagenet_utils.decode_predictions(results)\n",
        "Image.open(image_path + image_file_name)\n",
        "\n",
        "# Initialize video capture\n",
        "print('333')\n",
        "video_capture = cv2.VideoCapture('/content/drive/MyDrive/dataSamples/cat_video.mp4')  # Replace 'your_video.mp4' with the path to your video file\n",
        "print('444')\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process the frame\n",
        "    frame = cv2.resize(frame, (224, 224))  # Resize the frame to (224, 224)\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "    frame_copy = frame.copy()  # Create a copy of the frame to modify\n",
        "    frame_copy = tf.image.convert_image_dtype(frame_copy, tf.float32)  # Convert to float32\n",
        "    frame_copy = np.array(frame_copy)  # Convert to a NumPy array\n",
        "    frame_copy = np.expand_dims(frame_copy, axis=0)\n",
        "    preprocessed_frame = tf.keras.applications.mobilenet.preprocess_input(frame_copy)\n",
        "\n",
        "    # Make predictions\n",
        "    results = mobileNetModel.predict(preprocessed_frame)\n",
        "    decoded_predictions = imagenet_utils.decode_predictions(results)\n",
        "\n",
        "    # Display the frame and predictions\n",
        "\n",
        "    cv2_imshow(frame)\n",
        "    print(decoded_predictions)\n",
        "\n",
        "    # Exit when 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "print('55')\n",
        "# Release the video capture and close OpenCV windows\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ]
}